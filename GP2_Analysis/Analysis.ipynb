{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import re\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "import os\n",
    "\n",
    "# change this directory to a folder with all the files you want in it \n",
    "directory_path = '/home/seh6fy/git/dspg22ari2/BERT_Analysis/GAT'\n",
    "\n",
    "# list of file names in the directory\n",
    "list_of_files = os.listdir(directory_path)\n",
    "\n",
    "# initialize an empty dataframe to store the text documents\n",
    "df = pd.DataFrame(columns=['text'])\n",
    "\n",
    "for filename in list_of_files:\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    # check if the path is a file\n",
    "    if os.path.isfile(file_path):\n",
    "        # read the contents of the file and append as a new row to the dataframe\n",
    "        text = pd.read_csv(file_path, on_bad_lines='skip', encoding='utf-8', quoting=csv.QUOTE_NONE, lineterminator='.', header=None)[0].str.cat().strip()\n",
    "        df = pd.concat([df, pd.DataFrame({'text': [text]})], ignore_index=True)\n",
    "\n",
    "\n",
    "# this line is taking out the new lines so it doesn't display them all as separate documents\n",
    "df = df.replace(r'\\n',' ', regex=True)\n",
    "df = df.replace('\f",
    "', ' ', regex=True)\n",
    "\n",
    "import unicodedata\n",
    "df['text'] = df['text'].apply(lambda x: ''.join([' ' if not unicodedata.normalize('NFKD', char).encode('ASCII', 'ignore') else char for char in x]))\n",
    "\n",
    "model_name = 'gpt2'\n",
    "gp2_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Add padding token\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "def encode_document(text, max_tokens=5):\n",
    "    input_ids = tokenizer.encode(text, max_length=max_tokens, truncation=True, padding='max_length', return_tensors=\"pt\")\n",
    "    vector = gp2_model.transformer.wte.weight[input_ids,:]\n",
    "    document_embedding = torch.flatten(vector, start_dim=0, end_dim=1)\n",
    "    document_embedding = torch.flatten(document_embedding, start_dim=0, end_dim=1).detach().numpy()\n",
    "    return document_embedding\n",
    "\n",
    "#https://github.com/huggingface/transformers/issues/1458\n",
    "\n",
    "vectors = df['text'].apply(lambda x: encode_document(str(x)))\n",
    "output_vectors = pd.DataFrame(vectors.tolist())\n",
    "output_vectors = output_vectors.iloc[:, : 768]\n",
    "\n",
    "# Write the output vectors to a csv file\n",
    "# change the output vector name every time you change the folder\n",
    "output_vectors.to_csv('output_vectors_GAT_GP2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-jns]",
   "language": "python",
   "name": "conda-env-.conda-jns-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
